{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feede333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import tokenizer_from_json \n",
    "from random import randint\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import json\n",
    "\n",
    "classdict = {\n",
    "    \"greeting\": 0,\n",
    "    \"introduce\": 1,\n",
    "    \"goodbye\": 2,\n",
    "    \"thanks\": 3,\n",
    "    \"buyproduct\": 4,\n",
    "    \"payment\": 5,\n",
    "    \"noanswer\": 6\n",
    "}\n",
    "\n",
    "data_file = open('intents.json').read()\n",
    "intents = json.loads(data_file)\n",
    "\n",
    "maxsentencelen = 20\n",
    "ignore_words = ['?', '!', \".\", \",\", \"'s\"]\n",
    "\n",
    "def clean_contractions(text):\n",
    "    mapping = {\n",
    "        \"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "        \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "        \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "        \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \n",
    "        \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \n",
    "        \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
    "        \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \n",
    "        \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "        \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n",
    "        \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \n",
    "        \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \n",
    "        \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "        \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \n",
    "        \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \n",
    "        \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "        \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \n",
    "        \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \n",
    "        \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \n",
    "        \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \n",
    "        \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n",
    "        \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "        \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \n",
    "        \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "        \"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \n",
    "        \"you're\": \"you are\", \"you've\": \"you have\" \n",
    "    }\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
    "    return text\n",
    "\n",
    "def clean_special_chars(text):\n",
    "    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    return text\n",
    "\n",
    "def predictClass(text, model):\n",
    "    with open('tokenizer.json') as f:\n",
    "        datax = json.load(f)\n",
    "        for iw in ignore_words:\n",
    "            text = text.replace(iw, \"\")\n",
    "        text = text.lower()\n",
    "        text = clean_contractions(text)\n",
    "        text = clean_special_chars(text)\n",
    "\n",
    "        tokenizer = tokenizer_from_json(datax)\n",
    "        inputtext = tokenizer.texts_to_sequences([\"{}\".format(text)])\n",
    "        inputtext = pad_sequences(inputtext, maxlen=maxsentencelen)\n",
    "        outputclass = np.argmax(model.predict(inputtext),axis=1)\n",
    "    \n",
    "    return outputclass\n",
    "\n",
    "def BotResponse(classdict, text, model):\n",
    "    outputclass = predictClass(text, model)[0]\n",
    "    classname = list(classdict.keys())[list(classdict.values()).index(outputclass)]\n",
    "    for intent in intents['intents']:\n",
    "        if(intent['tag'] == classname): \n",
    "            response_len = len(intent['responses'])\n",
    "            randomid = randint(0, response_len - 1)\n",
    "            return intent['tag'],intent['responses'][randomid]\n",
    "\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d99113",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('word2vec_eng6_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41b447f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 20, 300)           30000     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 300)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               768128    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 799,031\n",
      "Trainable params: 799,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee861a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('buyproduct', 'Here are our list of products.')\n"
     ]
    }
   ],
   "source": [
    "print(BotResponse(classdict, \"I want to buy somethings\", model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca37aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean(sentence):\n",
    "#     # tokenize the pattern - split words into array\n",
    "#     sentence_words = nltk.word_tokenize(sentence)\n",
    "#     # stem each word - create short form for word\n",
    "#     sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "#     return sentence_words\n",
    "\n",
    "# # return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "# def bow(sentence, words):\n",
    "#     # tokenize the pattern\n",
    "#     sentence_words = clean(sentence)\n",
    "#     # bag of words - matrix of N words, vocabulary matrix\n",
    "#     bag = [0]*len(words) \n",
    "#     for s in sentence_words:\n",
    "#         for i,w in enumerate(words):\n",
    "#             if w == s: \n",
    "#                 # assign 1 if current word is in the vocabulary position\n",
    "#                 bag[i] = 1\n",
    "#     return(np.array(bag))\n",
    "\n",
    "# def predict_class(sentence, model):\n",
    "#     # filter out predictions below a threshold\n",
    "#     p = bow(sentence, words)\n",
    "#     res = model.predict(np.array([p]))[0]\n",
    "#     ERROR_THRESHOLD = 0.25\n",
    "# #     print(res)\n",
    "\n",
    "#     results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "#     # sort by strength of probability\n",
    "#     results.sort(key=lambda x: x[1], reverse=True)\n",
    "#     return_list = []\n",
    "#     for r in results:\n",
    "#         return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "#     return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6789d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getResponse(ints, intents_json):\n",
    "#     tag = ints[0]['intent']\n",
    "#     list_of_intents = intents_json['intents']\n",
    "#     for i in list_of_intents:\n",
    "#         if(i['tag']== tag):\n",
    "#             result = random.choice(i['responses'])\n",
    "#             break\n",
    "#     return result\n",
    "# def chatbot_response(text):\n",
    "#     ints = predict_class(text, model)\n",
    "#     predict_intent = ints[0]['intent']\n",
    "#     # print(ints)\n",
    "#     res = getResponse(ints, intents)\n",
    "    \n",
    "#     return res, ints[0]['intent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f060af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while(True):\n",
    "#     w = str(input())\n",
    "#     print(\"You: \", w)\n",
    "#     res = chatbot_response(w)\n",
    "#     print(\"Bot: \",res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ced7dd",
   "metadata": {},
   "source": [
    "## Create data for Online Shopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf57a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"books.csv\")\n",
    "\n",
    "arr = np.array(data)\n",
    "# print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b53ddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 101, 'book': 'The Lord of the Rings', 'author': 'J.R.R. Tolkien', 'price': 599999}\n",
      "{'id': 102, 'book': 'The Kite Runner', 'author': 'Khaled Hosseini', 'price': 649999}\n",
      "{'id': 103, 'book': 'Harry Potter and the Philosopher Stone', 'author': 'J.K. Rowling', 'price': 549999}\n",
      "{'id': 104, 'book': 'Slaughterhouse-Five', 'author': 'Kurt Vonnegut', 'price': 549999}\n",
      "{'id': 105, 'book': 'The Lion, the Witch, and the Wardrobe', 'author': 'C.S. Lewis', 'price': 549999}\n",
      "{'id': 106, 'book': 'To Kill a Mockingbird', 'author': 'Harper Lee', 'price': 599999}\n",
      "{'id': 107, 'book': 'The Book Thief', 'author': 'Markus Zusak', 'price': 499999}\n",
      "{'id': 108, 'book': 'Wuthering Heights', 'author': 'Emily Bronte', 'price': 649999}\n",
      "{'id': 109, 'book': 'The Catcher in the Rye', 'author': 'J.D. Salinger', 'price': 449999}\n",
      "{'id': 110, 'book': 'Animal Farm', 'author': 'George Orwell', 'price': 499999}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[{\"id\": 101, \"book\": \"The Lord of the Rings\", \"author\": \"J.R.R. Tolkien\", \"price\": 599999}, {\"id\": 102, \"book\": \"The Kite Runner\", \"author\": \"Khaled Hosseini\", \"price\": 649999}, {\"id\": 103, \"book\": \"Harry Potter and the Philosopher Stone\", \"author\": \"J.K. Rowling\", \"price\": 549999}, {\"id\": 104, \"book\": \"Slaughterhouse-Five\", \"author\": \"Kurt Vonnegut\", \"price\": 549999}, {\"id\": 105, \"book\": \"The Lion, the Witch, and the Wardrobe\", \"author\": \"C.S. Lewis\", \"price\": 549999}, {\"id\": 106, \"book\": \"To Kill a Mockingbird\", \"author\": \"Harper Lee\", \"price\": 599999}, {\"id\": 107, \"book\": \"The Book Thief\", \"author\": \"Markus Zusak\", \"price\": 499999}, {\"id\": 108, \"book\": \"Wuthering Heights\", \"author\": \"Emily Bronte\", \"price\": 649999}, {\"id\": 109, \"book\": \"The Catcher in the Rye\", \"author\": \"J.D. Salinger\", \"price\": 449999}, {\"id\": 110, \"book\": \"Animal Farm\", \"author\": \"George Orwell\", \"price\": 499999}]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = []\n",
    "for i in range(len(arr)):\n",
    "    pd = {\n",
    "        \"id\": arr[i][0],\n",
    "        \"book\": arr[i][1],\n",
    "        \"author\": arr[i][2],\n",
    "        \"price\": arr[i][3]\n",
    "    }\n",
    "    print(pd)\n",
    "    products.append(pd)\n",
    "products = json.dumps(products)\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027994c3",
   "metadata": {},
   "source": [
    "## Build the User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb3dbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, make_response\n",
    "from flask_cors import CORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc13fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:8000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [12/Dec/2021 08:37:25] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Dec/2021 08:37:25] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [12/Dec/2021 08:37:29] \"GET /get_bot?msg=%3Cspan%20class%20%3D%20%22message%20user%22%3E%20User%3A%20hello%3C%2Fspan%3E HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Dec/2021 08:37:37] \"GET /get_bot?msg=%3Cspan%20class%20%3D%20%22message%20user%22%3E%20User%3A%20have%20a%20nice%20day%3C%2Fspan%3E HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "CORS(app)\n",
    "app.config.update(\n",
    "    TEMPLATES_AUTO_RELOAD = True\n",
    ")\n",
    "path = \"main.html\"\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home_page():\n",
    "    return (render_template(\"main.html\"))\n",
    "\n",
    "@app.route('/products')\n",
    "def product_page():\n",
    "    return (render_template(\"products.html\"))\n",
    "\n",
    "@app.route(\"/payment\")\n",
    "def payment_page():\n",
    "    return render_template(\"payment.html\")\n",
    "\n",
    "@app.route(\"/get_products\")\n",
    "def get_products():  \n",
    "    res = make_response(products)\n",
    "#     res.set_cookie('cross-site-cookie', samesite='None', secure=True);\n",
    "    return res\n",
    "\n",
    "@app.route(\"/get_bot\")\n",
    "def bot_response():\n",
    "    text = request.args.get('msg')\n",
    "#     res = chatbot_response(text)\n",
    "    res = BotResponse(classdict, text, model)\n",
    "    data = json.dumps({\"intent\": res[0], \"response\": res[1]})    \n",
    "    return data\n",
    "\n",
    "def shutdown_server():\n",
    "    func = request.environ.get('werkzeug.server.shutdown')\n",
    "    if func is None:\n",
    "        raise RuntimeError('Not running with the Werkzeug Server')\n",
    "    func()\n",
    "\n",
    "@app.route('/shutdown', methods=['POST'])\n",
    "def shutdown():\n",
    "    shutdown_server()\n",
    "    return 'Server shutting down...'\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"localhost\", port=8000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fdc1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8255022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
